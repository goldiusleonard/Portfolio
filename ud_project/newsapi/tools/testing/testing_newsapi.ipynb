{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcase_list = [\"Religion Unity\", \"Race Polarization\", \"Race Artistry\", \"Race Bilingual\", \"Religion Healing\",\n",
    "                 \"Race Identity\", \"Royal Betrayal\", \"Religion Prayer\", \"Religion Values\", \"Royal Heritage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Royal Heritage Hate Speech Scam\n",
      "['Royal Heritage Hate Speech Scandal Investigation', 'Royal Heritage Company Hate Speech Allegations', 'Royal Heritage Hate Speech Scam Victims Speak Out', 'Royal Heritage Hate Speech Controversy and Lawsuits', 'Royal Heritage Hate Speech Scandal: Latest Updates and Developments']\n",
      "['Royal Heritage Hate Speech Scandal Investigation', 'Royal Heritage Company Hate Speech Allegations', 'Royal Heritage Hate Speech Scam Victims Speak Out', 'Royal Heritage Hate Speech Controversy and Lawsuits', 'Royal Heritage Hate Speech Scandal: Latest Updates and Developments']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# expanding the topic\n",
    "from openai import OpenAI\n",
    "import ast\n",
    "\n",
    "LLAMA70B_MODEL=\"hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4\"\n",
    "\n",
    "\n",
    "llama70b_client = OpenAI(\n",
    "    base_url=\"http://172.210.166.80:8001/v1\", api_key=\"llm_api_key_ABC123XYZ\"\n",
    ")\n",
    "\n",
    "def topic_expander(\n",
    "    topic):\n",
    "\n",
    "    print(topic)\n",
    "\n",
    "#     system_prompt = \"\"\"Instructions: Expand the query {topic} by including related concepts, synonyms, and broader or narrower terms. \n",
    "# Focus on generating a single, comprehensive list of terms or phrases. \n",
    "# Ensure that the most closely related and relevant terms are placed at the top of the list. \n",
    "# Avoid repetitive categories or splitting terms into sublists. \n",
    "# The expanded query should be suitable for applications like search engines, recommendation systems, or NLP tasks.\n",
    "# Do Not add any explanation. \n",
    "# The result should be a list of phrases.\n",
    "# The most relevant and related Phrase should be at the top of the list.\n",
    "# Do not include the {topic} in the list.\n",
    "# Write five expanded news queries based on the news query above to enhance the news searching. Output in a list format.\n",
    "# \"\"\"\n",
    "\n",
    "    system_prompt = \"\"\"Write five expanded news queries based on the news query below to enhance the news searching. \n",
    "Output in a python list format.\n",
    "Do not inlude any explanation\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"Examine the dict below.\n",
    "\n",
    "    news query:\n",
    "    {topic}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "    synonyms = llama70b_client.chat.completions.create(\n",
    "        model=LLAMA70B_MODEL,\n",
    "        messages=messages,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    synonyms = synonyms.choices[0].message.content\n",
    "    clean_output = synonyms.strip('```python').strip('```')\n",
    "\n",
    "    # Remove the \"news_queries =\" part\n",
    "    list_string = clean_output.split('=', 1)[1].strip()\n",
    "    news_queries = ast.literal_eval(list_string)\n",
    "    print(news_queries)\n",
    "\n",
    "    return news_queries\n",
    "\n",
    "# result_list = []\n",
    "# for topics in testcase_list:\n",
    "\n",
    "    # topic_dict =  {\"category\": \"\", \"sub_category\": \"Hate Speech\", \"topic\":topics}\n",
    "result = topic_expander(\"Royal Heritage Hate Speech Scam\")\n",
    " \n",
    "\n",
    "    \n",
    "    # result_list.append(result)\n",
    "\n",
    "# Filter out `None` values and combine the rest\n",
    "#maybe do this after the words are generated\n",
    "#topic = \" OR \".join(value for value in topic_dict.values() if value is not None)\n",
    "print(result)\n",
    "print(type(result))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Royal Betrayal\n",
      "Synonyms generated =  Here's an expanded query for the topic \"Royal Betrayal\" that includes related concepts, synonyms, and broader or narrower terms:\n",
      "\n",
      "1. Royal Treachery\n",
      "2. Regicide\n",
      "3. Palace Intrigue\n",
      "4. Court Conspiracy\n",
      "5. Monarch Assassination\n",
      "6. Royal Scandal\n",
      "7. Betrayal of the Crown\n",
      "8. Treason Against the King/Queen\n",
      "9. Royal Deception\n",
      "10. Power Struggle\n",
      "11. Throne Usurpation\n",
      "12. Royal Family Feud\n",
      "13. Loyalty Betrayed\n",
      "14. Kingdom Rebellion\n",
      "15. Aristocratic Conspiracy\n",
      "16. High Treason\n",
      "17. Royal Assassination Plot\n",
      "18. Court Politics\n",
      "19. Monarchy Overthrow\n",
      "20. Historical Betrayals\n",
      "\n",
      "This list can be used in various applications such as search engines, recommendation systems, or NLP tasks to capture the essence of the topic \"Royal Betrayal\" and its related concepts.\n",
      "Here's an expanded query for the topic \"Royal Betrayal\" that includes related concepts, synonyms, and broader or narrower terms:\n",
      "\n",
      "1. Royal Treachery\n",
      "2. Regicide\n",
      "3. Palace Intrigue\n",
      "4. Court Conspiracy\n",
      "5. Monarch Assassination\n",
      "6. Royal Scandal\n",
      "7. Betrayal of the Crown\n",
      "8. Treason Against the King/Queen\n",
      "9. Royal Deception\n",
      "10. Power Struggle\n",
      "11. Throne Usurpation\n",
      "12. Royal Family Feud\n",
      "13. Loyalty Betrayed\n",
      "14. Kingdom Rebellion\n",
      "15. Aristocratic Conspiracy\n",
      "16. High Treason\n",
      "17. Royal Assassination Plot\n",
      "18. Court Politics\n",
      "19. Monarchy Overthrow\n",
      "20. Historical Betrayals\n",
      "\n",
      "This list can be used in various applications such as search engines, recommendation systems, or NLP tasks to capture the essence of the topic \"Royal Betrayal\" and its related concepts.\n"
     ]
    }
   ],
   "source": [
    "# expanding the topic\n",
    "from openai import OpenAI\n",
    "\n",
    "LLAMA70B_MODEL=\"hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4\"\n",
    "\n",
    "\n",
    "llama70b_client = OpenAI(\n",
    "    base_url=\"http://172.210.166.80:8001/v1\", api_key=\"llm_api_key_ABC123XYZ\"\n",
    ")\n",
    "\n",
    "def topic_expander(\n",
    "    topic):\n",
    "\n",
    "    print(topic)\n",
    "\n",
    "    system_prompt = \"\"\"Instructions: Expand the query {topic} by including related concepts, synonyms, and broader or narrower terms. \n",
    "Focus on generating a single, comprehensive list of terms or phrases. \n",
    "Ensure that the most closely related and relevant terms are placed at the top of the list. \n",
    "Avoid repetitive categories or splitting terms into sublists. \n",
    "The expanded query should be suitable for applications like search engines, recommendation systems, or NLP tasks.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    user_prompt = f\"\"\"Examine the dict below.\n",
    "\n",
    "    Topic Dictionary:\n",
    "    {topic}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "    synonyms = llama70b_client.chat.completions.create(\n",
    "        model=LLAMA70B_MODEL,\n",
    "        messages=messages,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    synonyms = synonyms.choices[0].message.content\n",
    "    print(\"Result = \", synonyms)\n",
    "\n",
    "    return synonyms\n",
    "\n",
    "# result_list = []\n",
    "# for topics in testcase_list:\n",
    "\n",
    "    # topic_dict =  {\"category\": None, \"sub_category\": \"Hate Speech\", \"topic\":topics}\n",
    "result = topic_expander(\"Royal Betrayal\")\n",
    " \n",
    "    \n",
    "    # result_list.append(result)\n",
    "\n",
    "# Filter out `None` values and combine the rest\n",
    "#maybe do this after the words are generated\n",
    "#topic = \" OR \".join(value for value in topic_dict.values() if value is not None)\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Royal Betrayal\n",
      "Synonyms generated =  Expanded Query for \"Royal Betrayal\":\n",
      "\n",
      "1. Treason\n",
      "2. Regicide\n",
      "3. Royal Scandals\n",
      "4. Palace Intrigue\n",
      "5. Monarch Assassination\n",
      "6. Royal Family Feud\n",
      "7. High Treason\n",
      "8. Betrayal of the Crown\n",
      "9. Royal Deception\n",
      "10. Court Politics\n",
      "11. Loyalty and Deceit\n",
      "12. Power Struggle\n",
      "13. Royal Conspiracy\n",
      "14. Throne Usurpation\n",
      "15. Historical Betrayals\n",
      "\n",
      "Broader Terms:\n",
      "1. Royal History\n",
      "2. Monarchy\n",
      "3. Power Dynamics\n",
      "4. Loyalty and Betrayal\n",
      "5. Historical Events\n",
      "\n",
      "Narrower Terms:\n",
      "1. Specific royal betrayals (e.g., \"The Princes in the Tower\")\n",
      "2. Royal betrayals in fiction (e.g., \"Game of Thrones\")\n",
      "3. Royal assassination attempts (e.g., \"The Gunpowder Plot\")\n",
      "\n",
      "Synonyms:\n",
      "1. Treachery\n",
      "2. Deceit\n",
      "3. Disloyalty\n",
      "4. Infidelity\n",
      "5. Perfidy\n",
      "\n",
      "Related Concepts:\n",
      "1. Royal Succession\n",
      "2. Courtly Love\n",
      "3. Chivalry\n",
      "4. Honor and Loyalty\n",
      "5. State Secrets\n",
      "Expanded Query for \"Royal Betrayal\":\n",
      "\n",
      "1. Treason\n",
      "2. Regicide\n",
      "3. Royal Scandals\n",
      "4. Palace Intrigue\n",
      "5. Monarch Assassination\n",
      "6. Royal Family Feud\n",
      "7. High Treason\n",
      "8. Betrayal of the Crown\n",
      "9. Royal Deception\n",
      "10. Court Politics\n",
      "11. Loyalty and Deceit\n",
      "12. Power Struggle\n",
      "13. Royal Conspiracy\n",
      "14. Throne Usurpation\n",
      "15. Historical Betrayals\n",
      "\n",
      "Broader Terms:\n",
      "1. Royal History\n",
      "2. Monarchy\n",
      "3. Power Dynamics\n",
      "4. Loyalty and Betrayal\n",
      "5. Historical Events\n",
      "\n",
      "Narrower Terms:\n",
      "1. Specific royal betrayals (e.g., \"The Princes in the Tower\")\n",
      "2. Royal betrayals in fiction (e.g., \"Game of Thrones\")\n",
      "3. Royal assassination attempts (e.g., \"The Gunpowder Plot\")\n",
      "\n",
      "Synonyms:\n",
      "1. Treachery\n",
      "2. Deceit\n",
      "3. Disloyalty\n",
      "4. Infidelity\n",
      "5. Perfidy\n",
      "\n",
      "Related Concepts:\n",
      "1. Royal Succession\n",
      "2. Courtly Love\n",
      "3. Chivalry\n",
      "4. Honor and Loyalty\n",
      "5. State Secrets\n"
     ]
    }
   ],
   "source": [
    "# expanding the topic\n",
    "from openai import OpenAI\n",
    "\n",
    "LLAMA70B_MODEL=\"hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4\"\n",
    "\n",
    "\n",
    "llama70b_client = OpenAI(\n",
    "    base_url=\"http://172.210.166.80:8001/v1\", api_key=\"llm_api_key_ABC123XYZ\"\n",
    ")\n",
    "\n",
    "def topic_expander(\n",
    "    topic):\n",
    "\n",
    "    print(topic)\n",
    "\n",
    "    system_prompt = \"\"\"Instructions: \n",
    "Expand the query {topic} by including related concepts, \n",
    "    synonyms, and broader or narrower terms. Ensure the expansion enhances understanding while maintaining \n",
    "    relevance to the original intent. \n",
    "Provide the expanded query as a list of terms or phrases suitable for \n",
    "    diverse applications like search engines, recommendation systems, or NLP tasks.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    user_prompt = f\"\"\"Examine the dict below.\n",
    "\n",
    "    Topic Dictionary:\n",
    "    {topic}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "    synonyms = llama70b_client.chat.completions.create(\n",
    "        model=LLAMA70B_MODEL,\n",
    "        messages=messages,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    synonyms = synonyms.choices[0].message.content\n",
    "    print(\"Synonyms generated = \", synonyms)\n",
    "\n",
    "    return synonyms\n",
    "\n",
    "# result_list = []\n",
    "# for topics in testcase_list:\n",
    "\n",
    "    topic_dict =  {\"category\": None, \"sub_category\": \"Hate Speech\", \"topic\":topics}\n",
    "result = topic_expander(\"Royal Betrayal\")\n",
    " \n",
    "    \n",
    "    # result_list.append(result)\n",
    "\n",
    "# Filter out `None` values and combine the rest\n",
    "#maybe do this after the words are generated\n",
    "#topic = \" OR \".join(value for value in topic_dict.values() if value is not None)\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': None, 'sub_category': 'Hate Speech', 'topic': 'Royal Betrayal'}\n",
      "Synonyms generated =  Treachery, Disloyalty, Infidelity\n"
     ]
    }
   ],
   "source": [
    "# expanding the topic\n",
    "from openai import OpenAI\n",
    "\n",
    "LLAMA70B_LLM_BASE_URL=\"http://172.210.166.80:8001/v1\"\n",
    "LLAMA70B_LLM_API_KEY=\"llm_api_key_ABC123XYZ\"\n",
    "LLAMA70B_MODEL=\"hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4\"\n",
    "\n",
    "llama70b_client = OpenAI(\n",
    "    base_url=\"http://172.210.166.80:8001/v1\", api_key=\"llm_api_key_ABC123XYZ\"\n",
    ")\n",
    "\n",
    "def topic_expander(\n",
    "    topic_dict):\n",
    "\n",
    "    # Filter out `None` values and combine the rest\n",
    "    #maybe do this after the words are generated\n",
    "    #topic = \" OR \".join(value for value in topic_dict.values() if value is not None)\n",
    "\n",
    "    print(topic_dict)\n",
    "    \n",
    "\n",
    "    system_prompt = \"\"\"Instructions: \n",
    "- Examine the given dictionary and generate a maximum of 3 synonyms.\n",
    "- Synonyms are words related to the words in the dictionary.\n",
    "- The result should be a single string with all the related words.\n",
    "- Do NOT exceed 3 synonyms\n",
    "- Do NOT add any explanations\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"Examine the string below.\n",
    "\n",
    "    Topic Dictionary:\n",
    "    {topic_dict}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "    synonyms = llama70b_client.chat.completions.create(\n",
    "        model=LLAMA70B_MODEL,\n",
    "        messages=messages,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    synonyms = synonyms.choices[0].message.content\n",
    "    print(\"Synonyms generated = \", synonyms)\n",
    "\n",
    "\n",
    "topic_dict =  {\"category\": None, \"sub_category\": \"Hate Speech\", \"topic\":\"Royal Betrayal\"}\n",
    "topic_expander(topic_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved list to 11decnews_api.json\n"
     ]
    }
   ],
   "source": [
    "from newsapi import NewsApiClient\n",
    "import json\n",
    "\n",
    "testcase_list = [\"Religion Unity\", \"Race Polarization\", \"Race Artistry\", \"Race Bilingual\", \"Religion Healing\",\n",
    "                 \"Race Identity\", \"Royal Betrayal\", \"Religion Prayer\", \"Religion Values\", \"Royal Heritage\"]\n",
    "\n",
    "# Init\n",
    "newsapi = NewsApiClient(api_key='329c23695aee4fb286b376fb0d1a0a5c')\n",
    "\n",
    "response_list = []\n",
    "for topic in testcase_list:\n",
    "\n",
    "    all_articles = newsapi.get_everything(\n",
    "                        q=topic,\n",
    "                        language='en',\n",
    "                        sort_by='relevancy',\n",
    "                        page=1,\n",
    "                        page_size=5\n",
    "                        )\n",
    "    \n",
    "    # Check if articles were returned\n",
    "    if all_articles['status'] == 'ok' and all_articles['articles']:\n",
    "        # Prepare the data by including the topic\n",
    "        result_data = {\n",
    "            \"topic\": topic,\n",
    "            \"articles\": all_articles['articles']\n",
    "        }\n",
    "    \n",
    "        response_list.append(result_data)\n",
    "\n",
    "# # /v2/everything\n",
    "# all_articles = newsapi.get_everything(q='bitcoin',\n",
    "#                                     sources='bbc-news,the-verge',\n",
    "#                                     domains='bbc.co.uk,techcrunch.com',\n",
    "#                                     from_param='2024-12-01',\n",
    "#                                     to='2024-12-12',\n",
    "#                                     language='en',\n",
    "#                                     sort_by='relevancy',\n",
    "#                                     page=2)\n",
    "\n",
    "\n",
    "\n",
    "# Define the file name\n",
    "filename = \"11decnews_api.json\"\n",
    "\n",
    "# Save the list to a JSON file\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    json.dump(response_list, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved list to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the topic: Religion Unity\n",
      "500 {\"detail\":\"Internal Server Error: 404: No articles found.\"}\n",
      "response:  <Response [500]>\n",
      "this is the topic: Race Polarization\n",
      "500 {\"detail\":\"Internal Server Error: 404: No articles found.\"}\n",
      "response:  <Response [500]>\n",
      "this is the topic: Race Artistry\n",
      "500 {\"detail\":\"Internal Server Error: 404: No articles found.\"}\n",
      "response:  <Response [500]>\n",
      "this is the topic: Race Bilingual\n",
      "500 {\"detail\":\"Internal Server Error: 404: No articles found.\"}\n",
      "response:  <Response [500]>\n",
      "this is the topic: Religion Healing\n",
      "500 {\"detail\":\"Internal Server Error: 404: No articles found.\"}\n",
      "response:  <Response [500]>\n",
      "this is the topic: Race Identity\n",
      "500 {\"detail\":\"Internal Server Error: 404: No articles found.\"}\n",
      "response:  <Response [500]>\n",
      "this is the topic: Royal Betrayal\n",
      "500 {\"detail\":\"Internal Server Error: 404: No articles found.\"}\n",
      "response:  <Response [500]>\n",
      "this is the topic: Religion Prayer\n",
      "500 {\"detail\":\"Internal Server Error: 404: No articles found.\"}\n",
      "response:  <Response [500]>\n",
      "this is the topic: Religion Values\n",
      "500 {\"detail\":\"Internal Server Error: 404: No articles found.\"}\n",
      "response:  <Response [500]>\n",
      "this is the topic: Royal Heritage\n",
      "500 {\"detail\":\"Internal Server Error: 404: No articles found.\"}\n",
      "response:  <Response [500]>\n",
      "Responses saved to 'global_responses.json'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "responses = []\n",
    "\n",
    "for topic in testcase_list:\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"http://192.168.30.213:8020/fetch_news/\",\n",
    "            json={\n",
    "                \"tags\": [{\"type\": \"keyword\", \"value\": \"Petronas\"}],\n",
    "                \"perspective\": \"racism\",\n",
    "                \"fromDate\": \"2024-11-28\",\n",
    "                \"toDate\": \"2024-11-28\",\n",
    "                \"tiktok\": False,\n",
    "                \"news\": True,\n",
    "            },\n",
    "            verify=False,\n",
    "        )\n",
    "        \n",
    "        # Append the response content to the list\n",
    "        responses.append({\n",
    "            \"topic\": topic,\n",
    "            \"status_code\": response.status_code,\n",
    "            \"response\": response.json() if response.status_code == 200 else response.text\n",
    "        })\n",
    "\n",
    "        print(\"this is the topic:\", topic)\n",
    "        print(response.status_code, response.text) \n",
    "        print(\"response: \", response)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle connection or other errors\n",
    "        responses.append({\n",
    "            \"topic\": topic,\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "\n",
    "\n",
    "# Save the responses to a JSON file\n",
    "with open(\"responses.json\", \"w\") as file:\n",
    "    json.dump(responses, file, indent=4)\n",
    "\n",
    "print(\"Responses saved to 'global_responses.json'\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to extracted_articles.csv\n"
     ]
    }
   ],
   "source": [
    "# open  the json file,\n",
    "# extract necessary keys\n",
    "# put it in an excel file\n",
    "\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# Load the JSON data from the provided file\n",
    "file_path = 'newflow_responses.json'  # Replace with the path to your JSON file\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Prepare the CSV file for writing\n",
    "output_csv = 'extracted_articles.csv'  # Replace with your desired output path\n",
    "columns = ['topic', 'title', 'link', 'keywords', 'description', 'content']\n",
    "\n",
    "with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=columns)\n",
    "    writer.writeheader()  # Write the header row\n",
    "\n",
    "    # Process each item in the JSON data\n",
    "    for item in data:\n",
    "        topic = item.get('topic', '')\n",
    "        status_code = item.get('status_code', '')\n",
    "        response = item.get('response', {})\n",
    "\n",
    "        # Only process successful responses with articles\n",
    "        if status_code == 200 and isinstance(response, dict):\n",
    "            articles = response.get('articles', [])\n",
    "            for article in articles:\n",
    "                row = {\n",
    "                    'topic': topic,\n",
    "                    'title': article.get('title', ''),\n",
    "                    'link': article.get('link', ''),\n",
    "                    'keywords': ', '.join(article.get('keywords', [])) if article.get('keywords') else '',\n",
    "                    'description': article.get('description', ''),\n",
    "                    'content': article.get('content', '')\n",
    "                }\n",
    "                writer.writerow(row)  # Write the article data\n",
    "\n",
    "print(f\"Data successfully saved to {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
